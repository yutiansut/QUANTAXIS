# æ€§èƒ½ä¼˜åŒ–

**ç‰ˆæœ¬**: 2.1.0-alpha2
**ä½œè€…**: @yutiansut @quantaxis
**æ›´æ–°æ—¥æœŸ**: 2025-10-25

QUANTAXIS 2.1.0æä¾›äº†å¤šå±‚æ¬¡çš„æ€§èƒ½ä¼˜åŒ–æ–¹æ¡ˆï¼Œä»æ•°æ®å±‚åˆ°ç­–ç•¥å±‚å…¨é¢æå‡ç³»ç»Ÿæ€§èƒ½ã€‚

---

## ğŸ¯ æ€§èƒ½ä¼˜åŒ–æ¦‚è§ˆ

### ä¼˜åŒ–å±‚æ¬¡

1. **æ•°æ®å±‚ä¼˜åŒ–**: MongoDBç´¢å¼•ã€ClickHouseã€æ•°æ®ç¼“å­˜
2. **è®¡ç®—å±‚ä¼˜åŒ–**: RuståŠ é€Ÿã€å‘é‡åŒ–è®¡ç®—ã€å¹¶è¡Œå¤„ç†
3. **ç­–ç•¥å±‚ä¼˜åŒ–**: ç®—æ³•ä¼˜åŒ–ã€å†…å­˜ç®¡ç†ã€äº‹ä»¶é©±åŠ¨
4. **ç³»ç»Ÿå±‚ä¼˜åŒ–**: èµ„æºé…ç½®ã€è¿›ç¨‹ç®¡ç†ã€ç½‘ç»œä¼˜åŒ–

### æ€§èƒ½ç›®æ ‡

- **æ•°æ®æŸ¥è¯¢**: < 100ms (å•æ ‡çš„æ—¥çº¿1å¹´)
- **æŒ‡æ ‡è®¡ç®—**: < 10ms (MA/MACDç­‰å¸¸ç”¨æŒ‡æ ‡)
- **å›æµ‹é€Ÿåº¦**: > 1000 ticks/s
- **å®ç›˜å»¶è¿Ÿ**: < 50ms (Tick-to-Order)

---

## ğŸ“Š æ•°æ®å±‚ä¼˜åŒ–

### 1. MongoDBç´¢å¼•ä¼˜åŒ–

```python
from pymongo import MongoClient, ASCENDING, DESCENDING

client = MongoClient('mongodb://localhost:27017/')
db = client.quantaxis

# è‚¡ç¥¨æ—¥çº¿ç´¢å¼•
db.stock_day.create_index([
    ('code', ASCENDING),
    ('date_stamp', ASCENDING)
])

# å¤åˆç´¢å¼•ï¼ˆå¸¸ç”¨æŸ¥è¯¢ï¼‰
db.stock_day.create_index([
    ('code', ASCENDING),
    ('date', ASCENDING)
], background=True)

# æœŸè´§åˆ†é’Ÿçº¿ç´¢å¼•
db.future_min.create_index([
    ('code', ASCENDING),
    ('datetime', ASCENDING)
])

# æŸ¥çœ‹ç´¢å¼•ä½¿ç”¨æƒ…å†µ
explain = db.stock_day.find({
    'code': '000001',
    'date': {'$gte': '2024-01-01', '$lte': '2024-12-31'}
}).explain()

print(f"æŸ¥è¯¢è€—æ—¶: {explain['executionStats']['executionTimeMillis']}ms")
print(f"æ‰«ææ–‡æ¡£æ•°: {explain['executionStats']['totalDocsExamined']}")
```

### 2. æ•°æ®ç¼“å­˜ç­–ç•¥

```python
import QUANTAXIS as QA
from functools import lru_cache
import hashlib
import pickle

class DataCache:
    """æ•°æ®ç¼“å­˜ç®¡ç†"""
    
    def __init__(self, max_size=1000):
        self.cache = {}
        self.max_size = max_size
    
    def get_key(self, code, start, end, freq):
        """ç”Ÿæˆç¼“å­˜é”®"""
        key_str = f"{code}_{start}_{end}_{freq}"
        return hashlib.md5(key_str.encode()).hexdigest()
    
    def get(self, code, start, end, freq):
        """è·å–ç¼“å­˜æ•°æ®"""
        key = self.get_key(code, start, end, freq)
        return self.cache.get(key)
    
    def set(self, code, start, end, freq, data):
        """è®¾ç½®ç¼“å­˜æ•°æ®"""
        if len(self.cache) >= self.max_size:
            # LRUæ·˜æ±°
            oldest_key = next(iter(self.cache))
            del self.cache[oldest_key]
        
        key = self.get_key(code, start, end, freq)
        self.cache[key] = data
    
    def clear(self):
        """æ¸…ç©ºç¼“å­˜"""
        self.cache.clear()

# ä½¿ç”¨ç¤ºä¾‹
cache = DataCache(max_size=500)

def fetch_stock_data_cached(code, start, end):
    """å¸¦ç¼“å­˜çš„æ•°æ®è·å–"""
    # æ£€æŸ¥ç¼“å­˜
    data = cache.get(code, start, end, 'day')
    if data is not None:
        return data
    
    # ä»æ•°æ®åº“è·å–
    data = QA.QA_fetch_stock_day(code, start, end)
    
    # å†™å…¥ç¼“å­˜
    cache.set(code, start, end, 'day', data)
    return data

# ä½¿ç”¨LRUç¼“å­˜è£…é¥°å™¨
@lru_cache(maxsize=100)
def get_stock_list():
    """è·å–è‚¡ç¥¨åˆ—è¡¨ï¼ˆç¼“å­˜ï¼‰"""
    return QA.QA_fetch_stock_list()
```

### 3. ClickHouseé›†æˆ

```python
from clickhouse_driver import Client
import pandas as pd

class ClickHouseData:
    """ClickHouseæ•°æ®è®¿é—®"""
    
    def __init__(self, host='localhost', port=9000):
        self.client = Client(host=host, port=port)
    
    def create_stock_table(self):
        """åˆ›å»ºè‚¡ç¥¨è¡¨"""
        self.client.execute('''
            CREATE TABLE IF NOT EXISTS stock_day (
                code String,
                date Date,
                open Float64,
                high Float64,
                low Float64,
                close Float64,
                volume UInt64,
                date_stamp UInt32
            ) ENGINE = MergeTree()
            PARTITION BY toYYYYMM(date)
            ORDER BY (code, date)
        ''')
    
    def insert_data(self, df):
        """æ‰¹é‡æ’å…¥æ•°æ®"""
        data = df.to_dict('records')
        self.client.execute(
            'INSERT INTO stock_day VALUES',
            data
        )
    
    def query_stock(self, code, start, end):
        """é«˜æ€§èƒ½æŸ¥è¯¢"""
        query = f'''
            SELECT *
            FROM stock_day
            WHERE code = '{code}'
            AND date >= '{start}'
            AND date <= '{end}'
            ORDER BY date
        '''
        
        result = self.client.execute(query)
        columns = ['code', 'date', 'open', 'high', 'low', 'close', 'volume', 'date_stamp']
        return pd.DataFrame(result, columns=columns)

# ä½¿ç”¨ç¤ºä¾‹
ch = ClickHouseData()
data = ch.query_stock('000001', '2024-01-01', '2024-12-31')
print(f"æŸ¥è¯¢è€—æ—¶: < 50ms (vs MongoDB 200ms+)")
```

---

## âš¡ è®¡ç®—å±‚ä¼˜åŒ–

### 1. RuståŠ é€Ÿ

```python
import qars2
import numpy as np
import time

# æ€§èƒ½å¯¹æ¯”
data = np.random.rand(100000)

# Pythonå®ç°
start = time.time()
result_py = []
for i in range(20, len(data)):
    result_py.append(np.mean(data[i-20:i]))
python_time = time.time() - start

# Rustå®ç°
start = time.time()
result_rust = qars2.ma(data, 20)
rust_time = time.time() - start

print(f"Pythonè€—æ—¶: {python_time*1000:.2f}ms")
print(f"Rustè€—æ—¶: {rust_time*1000:.2f}ms")
print(f"åŠ é€Ÿæ¯”: {python_time/rust_time:.0f}x")
```

### 2. å‘é‡åŒ–è®¡ç®—

```python
import numpy as np
import pandas as pd

# âŒ ä½æ•ˆï¼šå¾ªç¯è®¡ç®—
def calculate_returns_slow(prices):
    returns = []
    for i in range(1, len(prices)):
        returns.append((prices[i] - prices[i-1]) / prices[i-1])
    return returns

# âœ… é«˜æ•ˆï¼šå‘é‡åŒ–
def calculate_returns_fast(prices):
    return prices.pct_change().fillna(0)

# æ€§èƒ½å¯¹æ¯”
prices = pd.Series(np.random.rand(100000))

%timeit calculate_returns_slow(prices)  # çº¦ 50ms
%timeit calculate_returns_fast(prices)  # çº¦ 1ms

# âŒ ä½æ•ˆï¼šé€è¡ŒDataFrameæ“ä½œ
def process_dataframe_slow(df):
    results = []
    for idx, row in df.iterrows():
        results.append(row['close'] * row['volume'])
    return results

# âœ… é«˜æ•ˆï¼šå‘é‡åŒ–æ“ä½œ
def process_dataframe_fast(df):
    return df['close'] * df['volume']
```

### 3. å¹¶è¡Œè®¡ç®—

```python
from multiprocessing import Pool, cpu_count
import QUANTAXIS as QA

def calculate_indicators(code):
    """è®¡ç®—å•ä¸ªæ ‡çš„æŒ‡æ ‡"""
    data = QA.QA_fetch_stock_day(code, '2024-01-01', '2024-12-31')
    
    # è®¡ç®—æŒ‡æ ‡
    ma5 = QA.MA(data['close'], 5)
    ma20 = QA.MA(data['close'], 20)
    
    return {
        'code': code,
        'ma5': ma5.iloc[-1],
        'ma20': ma20.iloc[-1]
    }

# ä¸²è¡Œå¤„ç†
codes = QA.QA_fetch_stock_list()['code'].tolist()[:100]

start = time.time()
results_serial = [calculate_indicators(code) for code in codes]
serial_time = time.time() - start

# å¹¶è¡Œå¤„ç†
start = time.time()
with Pool(processes=cpu_count()) as pool:
    results_parallel = pool.map(calculate_indicators, codes)
parallel_time = time.time() - start

print(f"ä¸²è¡Œè€—æ—¶: {serial_time:.2f}s")
print(f"å¹¶è¡Œè€—æ—¶: {parallel_time:.2f}s")
print(f"åŠ é€Ÿæ¯”: {serial_time/parallel_time:.2f}x")
```

### 4. NumPyä¼˜åŒ–æŠ€å·§

```python
import numpy as np

# âœ… ä½¿ç”¨NumPyå†…ç½®å‡½æ•°
data = np.array([1, 2, 3, 4, 5])
result = np.sum(data)  # å¿«
# è€Œä¸æ˜¯ sum(data)    # æ…¢

# âœ… é¢„åˆ†é…æ•°ç»„
n = 100000
result = np.zeros(n)  # é¢„åˆ†é…
for i in range(n):
    result[i] = i * 2

# âŒ é¿å…åŠ¨æ€æ‰©å±•
# result = []
# for i in range(n):
#     result.append(i * 2)

# âœ… ä½¿ç”¨è§†å›¾è€Œéå¤åˆ¶
arr = np.random.rand(10000)
view = arr[100:200]  # è§†å›¾ï¼Œä¸å¤åˆ¶æ•°æ®
# copy = arr[100:200].copy()  # å¤åˆ¶ï¼Œè€—è´¹å†…å­˜

# âœ… ä½¿ç”¨å¹¿æ’­
a = np.array([[1, 2, 3]])
b = np.array([[1], [2], [3]])
result = a + b  # å¹¿æ’­ï¼Œé«˜æ•ˆ
```

---

## ğŸ”§ ç­–ç•¥å±‚ä¼˜åŒ–

### 1. ç®—æ³•ä¼˜åŒ–

```python
from QUANTAXIS.QAStrategy import QAStrategyCtaBase
import numpy as np

class OptimizedStrategy(QAStrategyCtaBase):
    """ä¼˜åŒ–çš„ç­–ç•¥"""
    
    def user_init(self):
        self.ma_period = 20
        
        # âœ… é¢„è®¡ç®—å›ºå®šå€¼
        self.position_size = self.init_cash * 0.2
        
        # âœ… ä½¿ç”¨dequeå­˜å‚¨å†å²æ•°æ®
        from collections import deque
        self.price_buffer = deque(maxlen=self.ma_period)
    
    def on_bar(self, bar):
        # âœ… é¿å…é‡å¤è·å–æ•°æ®
        self.price_buffer.append(bar.close)
        
        if len(self.price_buffer) < self.ma_period:
            return
        
        # âœ… ä½¿ç”¨NumPyè®¡ç®—ï¼ˆå¿«ï¼‰
        ma = np.mean(self.price_buffer)
        
        # âŒ è€Œéæ¯æ¬¡é‡æ–°è·å–å’Œè®¡ç®—ï¼ˆæ…¢ï¼‰
        # market_data = self.get_code_marketdata(bar.code)
        # ma = sum([x['close'] for x in market_data[-20:]]) / 20
        
        # äº¤æ˜“é€»è¾‘
        positions = self.acc.positions
        if bar.close > ma and bar.code not in positions:
            self.BuyOpen(bar.code, 1)
        elif bar.close < ma and bar.code in positions:
            self.SellClose(bar.code, 1)
```

### 2. å†…å­˜ä¼˜åŒ–

```python
import sys
import gc

class MemoryOptimizedStrategy(QAStrategyCtaBase):
    """å†…å­˜ä¼˜åŒ–ç­–ç•¥"""
    
    def user_init(self):
        # âœ… ä½¿ç”¨ç”Ÿæˆå™¨è€Œéåˆ—è¡¨
        self.data_generator = self.get_data_generator()
        
        # âœ… åªä¿ç•™å¿…è¦çš„å†å²æ•°æ®
        self.max_history = 100
        self.price_history = []
    
    def get_data_generator(self):
        """ç”Ÿæˆå™¨æ¨¡å¼"""
        for bar in self.market_data:
            yield bar
    
    def on_bar(self, bar):
        # âœ… é™åˆ¶å†å²æ•°æ®å¤§å°
        self.price_history.append(bar.close)
        if len(self.price_history) > self.max_history:
            self.price_history.pop(0)
        
        # âœ… å®šæœŸå›æ”¶åƒåœ¾
        if bar.datetime.minute == 0:
            gc.collect()
    
    def get_memory_usage(self):
        """è·å–å†…å­˜ä½¿ç”¨"""
        import psutil
        process = psutil.Process()
        return process.memory_info().rss / 1024 / 1024  # MB
```

### 3. å‡å°‘I/Oæ“ä½œ

```python
class IOOptimizedStrategy(QAStrategyCtaBase):
    """I/Oä¼˜åŒ–ç­–ç•¥"""
    
    def user_init(self):
        # âœ… é¢„åŠ è½½æ•°æ®
        self.preload_data()
        
        # âœ… æ‰¹é‡å†™å…¥æ—¥å¿—
        self.log_buffer = []
        self.log_batch_size = 100
    
    def preload_data(self):
        """é¢„åŠ è½½æ‰€æœ‰éœ€è¦çš„æ•°æ®"""
        self.stock_list = QA.QA_fetch_stock_list()
        self.index_data = QA.QA_fetch_index_day('000001', self.start, self.end)
    
    def on_bar(self, bar):
        # ç­–ç•¥é€»è¾‘
        pass
    
    def log_trade(self, trade_info):
        """æ‰¹é‡æ—¥å¿—"""
        self.log_buffer.append(trade_info)
        
        if len(self.log_buffer) >= self.log_batch_size:
            self.flush_logs()
    
    def flush_logs(self):
        """æ‰¹é‡å†™å…¥"""
        with open('trades.log', 'a') as f:
            for log in self.log_buffer:
                f.write(log + '\n')
        self.log_buffer.clear()
```

---

## ğŸš€ å›æµ‹ä¼˜åŒ–

### 1. å¹¶è¡Œå›æµ‹

```python
from multiprocessing import Pool
import QUANTAXIS as QA

def run_single_backtest(params):
    """å•æ¬¡å›æµ‹"""
    fast_period, slow_period = params
    
    strategy = DualMAStrategy(
        code='rb2501',
        frequence='5min',
        start='2024-01-01',
        end='2024-12-31',
        fast_period=fast_period,
        slow_period=slow_period
    )
    strategy.run_backtest()
    
    return {
        'params': params,
        'return': strategy.acc.total_return,
        'sharpe': strategy.acc.sharpe
    }

# å‚æ•°ç»„åˆ
param_grid = [
    (5, 20), (5, 30), (5, 40),
    (10, 20), (10, 30), (10, 40),
    (15, 20), (15, 30), (15, 40)
]

# å¹¶è¡Œå›æµ‹
with Pool(processes=4) as pool:
    results = pool.map(run_single_backtest, param_grid)

# æ‰¾å‡ºæœ€ä¼˜å‚æ•°
best_result = max(results, key=lambda x: x['sharpe'])
print(f"æœ€ä¼˜å‚æ•°: {best_result['params']}")
print(f"å¤æ™®æ¯”ç‡: {best_result['sharpe']:.2f}")
```

### 2. å¢é‡å›æµ‹

```python
class IncrementalBacktest:
    """å¢é‡å›æµ‹"""
    
    def __init__(self):
        self.last_end_date = None
        self.acc_state = None
    
    def run_backtest(self, start, end, incremental=True):
        """å¢é‡è¿è¡Œå›æµ‹"""
        if incremental and self.last_end_date:
            # åªå›æµ‹æ–°æ•°æ®
            start = self.last_end_date
            # æ¢å¤è´¦æˆ·çŠ¶æ€
            strategy.acc = self.acc_state
        
        strategy = MyStrategy(
            code='rb2501',
            start=start,
            end=end
        )
        strategy.run_backtest()
        
        # ä¿å­˜çŠ¶æ€
        self.last_end_date = end
        self.acc_state = strategy.acc
        
        return strategy.acc

# ä½¿ç”¨ç¤ºä¾‹
backtester = IncrementalBacktest()

# åˆæ¬¡å›æµ‹
acc1 = backtester.run_backtest('2024-01-01', '2024-06-30')

# å¢é‡å›æµ‹ï¼ˆåªè®¡ç®—æ–°æ•°æ®ï¼‰
acc2 = backtester.run_backtest('2024-01-01', '2024-12-31', incremental=True)
```

---

## ğŸ“ˆ æ€§èƒ½ç›‘æ§

### 1. æ€§èƒ½åˆ†æ

```python
import cProfile
import pstats
from io import StringIO

def profile_strategy():
    """æ€§èƒ½åˆ†æ"""
    profiler = cProfile.Profile()
    profiler.enable()
    
    # è¿è¡Œç­–ç•¥
    strategy = MyStrategy(
        code='rb2501',
        start='2024-01-01',
        end='2024-12-31'
    )
    strategy.run_backtest()
    
    profiler.disable()
    
    # è¾“å‡ºç»“æœ
    s = StringIO()
    ps = pstats.Stats(profiler, stream=s).sort_stats('cumulative')
    ps.print_stats(20)
    print(s.getvalue())

profile_strategy()
```

### 2. å†…å­˜åˆ†æ

```python
from memory_profiler import profile

@profile
def memory_intensive_function():
    """å†…å­˜å¯†é›†å‹å‡½æ•°"""
    data = QA.QA_fetch_stock_day('000001', '2020-01-01', '2024-12-31')
    
    # è®¡ç®—æŒ‡æ ‡
    ma5 = QA.MA(data['close'], 5)
    ma20 = QA.MA(data['close'], 20)
    
    return ma5, ma20

# è¿è¡Œåˆ†æ
memory_intensive_function()
```

### 3. å®æ—¶ç›‘æ§

```python
import time
import psutil

class PerformanceMonitor:
    """æ€§èƒ½ç›‘æ§"""
    
    def __init__(self):
        self.start_time = None
        self.bar_count = 0
    
    def start(self):
        """å¼€å§‹ç›‘æ§"""
        self.start_time = time.time()
        self.bar_count = 0
    
    def on_bar(self):
        """æ¯ä¸ªbarè°ƒç”¨"""
        self.bar_count += 1
        
        # æ¯1000ä¸ªbarè¾“å‡ºä¸€æ¬¡
        if self.bar_count % 1000 == 0:
            elapsed = time.time() - self.start_time
            tps = self.bar_count / elapsed
            
            # CPUå’Œå†…å­˜
            cpu = psutil.cpu_percent()
            memory = psutil.Process().memory_info().rss / 1024 / 1024
            
            print(f"æ€§èƒ½: {tps:.0f} ticks/s, CPU: {cpu}%, å†…å­˜: {memory:.0f}MB")

# ä½¿ç”¨ç¤ºä¾‹
monitor = PerformanceMonitor()
monitor.start()

for bar in bars:
    # ç­–ç•¥é€»è¾‘
    monitor.on_bar()
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. æ•°æ®å±‚

- âœ… ä¸ºå¸¸ç”¨æŸ¥è¯¢å­—æ®µå»ºç«‹ç´¢å¼•
- âœ… ä½¿ç”¨ClickHouseå¤„ç†å¤§è§„æ¨¡æ•°æ®åˆ†æ
- âœ… å®ç°å¤šçº§ç¼“å­˜ç­–ç•¥ï¼ˆå†…å­˜â†’Redisâ†’MongoDBï¼‰
- âœ… æ‰¹é‡è¯»å–æ•°æ®ï¼Œå‡å°‘æ•°æ®åº“æŸ¥è¯¢æ¬¡æ•°
- âŒ é¿å…åœ¨å¾ªç¯ä¸­æŸ¥è¯¢æ•°æ®åº“

### 2. è®¡ç®—å±‚

- âœ… ä¼˜å…ˆä½¿ç”¨RuståŠ é€Ÿå…³é”®è®¡ç®—
- âœ… ä½¿ç”¨NumPyå‘é‡åŒ–æ“ä½œ
- âœ… å¹¶è¡Œè®¡ç®—å¤šæ ‡çš„æ•°æ®
- âœ… é¢„è®¡ç®—å›ºå®šå€¼ï¼Œé¿å…é‡å¤è®¡ç®—
- âŒ é¿å…Pythonå¾ªç¯ï¼Œä½¿ç”¨å‘é‡åŒ–

### 3. ç­–ç•¥å±‚

- âœ… ä½¿ç”¨dequeå­˜å‚¨æœ‰é™å†å²æ•°æ®
- âœ… å‡å°‘ä¸å¿…è¦çš„I/Oæ“ä½œ
- âœ… å®šæœŸå›æ”¶åƒåœ¾
- âœ… ä½¿ç”¨ç”Ÿæˆå™¨å¤„ç†å¤§æ•°æ®é›†
- âŒ é¿å…åœ¨on_barä¸­è¿›è¡Œå¤æ‚è®¡ç®—

### 4. ç³»ç»Ÿå±‚

- âœ… ä½¿ç”¨SSDå­˜å‚¨æ•°æ®åº“
- âœ… é…ç½®è¶³å¤Ÿçš„å†…å­˜ï¼ˆæ¨è32GB+ï¼‰
- âœ… ä½¿ç”¨å¤šæ ¸CPUå¹¶è¡Œå¤„ç†
- âœ… ä¼˜åŒ–ç½‘ç»œé…ç½®ï¼ˆå®ç›˜ï¼‰
- âŒ é¿å…åœ¨è™šæ‹Ÿæœºä¸­è¿è¡Œé«˜é¢‘ç­–ç•¥

---

## ğŸ“Š æ€§èƒ½åŸºå‡†

### å…¸å‹æ“ä½œæ€§èƒ½

| æ“ä½œ | æœªä¼˜åŒ– | ä¼˜åŒ–å | æå‡ |
|------|--------|--------|------|
| è‚¡ç¥¨æ—¥çº¿æŸ¥è¯¢ï¼ˆ1å¹´ï¼‰ | 500ms | 50ms | 10x |
| MAè®¡ç®—ï¼ˆ10ä¸‡ç‚¹ï¼‰ | 100ms | 1ms | 100x |
| å•æ ‡çš„å›æµ‹ï¼ˆ1å¹´åˆ†é’Ÿï¼‰ | 30s | 3s | 10x |
| 100æ ‡çš„å¹¶è¡Œå› å­è®¡ç®— | 120s | 15s | 8x |
| å®ç›˜Tickå»¶è¿Ÿ | 200ms | 30ms | 6.7x |

---

## ğŸ”— ç›¸å…³èµ„æº

- **Rusté›†æˆ**: [Rusté›†æˆæ–‡æ¡£](./rust-integration.md)
- **æ•°æ®è·å–**: [æ•°æ®è·å–æŒ‡å—](../user-guide/data-fetching.md)
- **ç­–ç•¥å¼€å‘**: [ç­–ç•¥å¼€å‘æŒ‡å—](../user-guide/strategy-development.md)

---

## ğŸ“ æ€»ç»“

QUANTAXISæ€§èƒ½ä¼˜åŒ–è¦ç‚¹ï¼š

âœ… **æ•°æ®å±‚**: MongoDBç´¢å¼• + ClickHouse + å¤šçº§ç¼“å­˜  
âœ… **è®¡ç®—å±‚**: RuståŠ é€Ÿ + å‘é‡åŒ– + å¹¶è¡Œè®¡ç®—  
âœ… **ç­–ç•¥å±‚**: ç®—æ³•ä¼˜åŒ– + å†…å­˜ç®¡ç† + I/Oå‡å°‘  
âœ… **ç›‘æ§**: æ€§èƒ½åˆ†æ + å®æ—¶ç›‘æ§ + æŒç»­ä¼˜åŒ–  

---

**ä½œè€…**: @yutiansut @quantaxis
**æœ€åæ›´æ–°**: 2025-10-25

[è¿”å›é«˜çº§åŠŸèƒ½](../README.md)
